{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "monan.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wBrIo9cCp9lY",
        "outputId": "59dab017-0a83-4e75-e64a-5caeb25dbb67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#initialising the CNN\n",
        "classifier = Sequential()\n",
        "#step1 - Convolution\n",
        "from keras.layers import Dense, Dropout\n",
        "classifier.add(Conv2D(128, (3,3), activation='relu',kernel_initializer='he_uniform',padding='same',input_shape=(150,150,3)))\n",
        "classifier.add(MaxPooling2D(pool_size =(2, 2)))\n",
        "classifier.add(Conv2D(32, (3, 3), activation='relu',kernel_initializer='he_uniform',padding='same'))\n",
        "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "classifier.add(Flatten())\n",
        "classifier.add(Dense(units = 128, activation= 'relu',kernel_initializer = 'he_uniform'))\n",
        "classifier.add(Dropout(0.2))\n",
        "classifier.add(Dense(units = 10, activation = 'softmax')) #Bao nhiêu người thì units = x bấy nhiêu\n",
        "\n",
        "#Compiling the CNN\n",
        "classifier.compile(optimizer = 'adam', loss='categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)\n",
        "training_set=train_datagen.flow_from_directory('/content/drive/MyDrive/monan/train',\n",
        "                                               target_size=(150,150),\n",
        "                                               batch_size=32,\n",
        "                                               class_mode ='categorical')\n",
        "test_set=train_datagen.flow_from_directory('/content/drive/MyDrive/monan/test',\n",
        "                                               target_size=(150,150),\n",
        "                                               batch_size=32,\n",
        "                                               class_mode ='categorical')\n",
        "\n",
        "#from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint \n",
        "#callbacks = [EarlyStopping(monitor = 'val_loss', patience =100), ModelCheckpoint('model_checkpoint_new.h5', save_best_only True)] \n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy',metrics = ['accuracy'])\n",
        "callbacks=[EarlyStopping(monitor='val_loss',patience=100)]\n",
        "\n",
        "history=classifier.fit(training_set,\n",
        "                  steps_per_epoch=len(training_set),\n",
        "                  batch_size = 64,\n",
        "                  epochs=30,\n",
        "                  validation_data=test_set,\n",
        "                  validation_steps=len(test_set),\n",
        "                  callbacks=callbacks,\n",
        "                  verbose = 1)\n",
        "\n",
        "#đánh giá chất lượng của mô hình và vẽ lại\n",
        "score = classifier.evaluate(test_set,verbose=0)\n",
        "print('Sai số kiểm tra là: ',score[0])\n",
        "print('Độ chính xác kiểm tra là: ',score[1])\n",
        "print('Done Train')\n",
        "classifier.save('classifier_VietNameseFOOD.h5')\n",
        "print('Done Save')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "82GKOnbnqC0T",
        "outputId": "c39ace19-0b4d-422d-d7d9-6022c05b1fe2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 600 images belonging to 10 classes.\n",
            "Found 240 images belonging to 10 classes.\n",
            "Epoch 1/30\n",
            "19/19 [==============================] - 62s 3s/step - loss: 5.1798 - accuracy: 0.1150 - val_loss: 2.1342 - val_accuracy: 0.2167\n",
            "Epoch 2/30\n",
            "19/19 [==============================] - 56s 3s/step - loss: 2.1408 - accuracy: 0.2067 - val_loss: 2.0296 - val_accuracy: 0.3000\n",
            "Epoch 3/30\n",
            "19/19 [==============================] - 58s 3s/step - loss: 1.9713 - accuracy: 0.3133 - val_loss: 1.7401 - val_accuracy: 0.4333\n",
            "Epoch 4/30\n",
            "19/19 [==============================] - 58s 3s/step - loss: 1.5864 - accuracy: 0.4217 - val_loss: 1.2243 - val_accuracy: 0.5917\n",
            "Epoch 5/30\n",
            "19/19 [==============================] - 58s 3s/step - loss: 1.2767 - accuracy: 0.5717 - val_loss: 1.1204 - val_accuracy: 0.6250\n",
            "Epoch 6/30\n",
            "19/19 [==============================] - 58s 3s/step - loss: 0.9440 - accuracy: 0.7033 - val_loss: 0.7470 - val_accuracy: 0.7833\n",
            "Epoch 7/30\n",
            "19/19 [==============================] - 58s 3s/step - loss: 0.8287 - accuracy: 0.7417 - val_loss: 0.6389 - val_accuracy: 0.8042\n",
            "Epoch 8/30\n",
            "19/19 [==============================] - 57s 3s/step - loss: 0.6912 - accuracy: 0.7867 - val_loss: 0.3957 - val_accuracy: 0.8958\n",
            "Epoch 9/30\n",
            "19/19 [==============================] - 56s 3s/step - loss: 0.6898 - accuracy: 0.8000 - val_loss: 0.4106 - val_accuracy: 0.8792\n",
            "Epoch 10/30\n",
            "19/19 [==============================] - 56s 3s/step - loss: 0.4811 - accuracy: 0.8283 - val_loss: 0.2162 - val_accuracy: 0.9417\n",
            "Epoch 11/30\n",
            "19/19 [==============================] - 56s 3s/step - loss: 0.3997 - accuracy: 0.8733 - val_loss: 0.2482 - val_accuracy: 0.9333\n",
            "Epoch 12/30\n",
            "19/19 [==============================] - 57s 3s/step - loss: 0.2846 - accuracy: 0.9217 - val_loss: 0.1136 - val_accuracy: 0.9708\n",
            "Epoch 13/30\n",
            "19/19 [==============================] - 55s 3s/step - loss: 0.2482 - accuracy: 0.9217 - val_loss: 0.1214 - val_accuracy: 0.9708\n",
            "Epoch 14/30\n",
            "19/19 [==============================] - 57s 3s/step - loss: 0.2405 - accuracy: 0.9300 - val_loss: 0.1177 - val_accuracy: 0.9708\n",
            "Epoch 15/30\n",
            "19/19 [==============================] - 56s 3s/step - loss: 0.2207 - accuracy: 0.9467 - val_loss: 0.1913 - val_accuracy: 0.9333\n",
            "Epoch 16/30\n",
            "19/19 [==============================] - 57s 3s/step - loss: 0.1480 - accuracy: 0.9550 - val_loss: 0.0761 - val_accuracy: 0.9750\n",
            "Epoch 17/30\n",
            "19/19 [==============================] - 55s 3s/step - loss: 0.2146 - accuracy: 0.9400 - val_loss: 0.1343 - val_accuracy: 0.9708\n",
            "Epoch 18/30\n",
            "19/19 [==============================] - 55s 3s/step - loss: 0.1217 - accuracy: 0.9650 - val_loss: 0.0633 - val_accuracy: 0.9833\n",
            "Epoch 19/30\n",
            "19/19 [==============================] - 55s 3s/step - loss: 0.1342 - accuracy: 0.9550 - val_loss: 0.0585 - val_accuracy: 0.9833\n",
            "Epoch 20/30\n",
            "19/19 [==============================] - 54s 3s/step - loss: 0.1465 - accuracy: 0.9483 - val_loss: 0.0809 - val_accuracy: 0.9792\n",
            "Epoch 21/30\n",
            "19/19 [==============================] - 54s 3s/step - loss: 0.1370 - accuracy: 0.9617 - val_loss: 0.0524 - val_accuracy: 0.9792\n",
            "Epoch 22/30\n",
            "19/19 [==============================] - 54s 3s/step - loss: 0.1069 - accuracy: 0.9733 - val_loss: 0.0374 - val_accuracy: 0.9917\n",
            "Epoch 23/30\n",
            "19/19 [==============================] - 54s 3s/step - loss: 0.1231 - accuracy: 0.9583 - val_loss: 0.0297 - val_accuracy: 1.0000\n",
            "Epoch 24/30\n",
            "19/19 [==============================] - 54s 3s/step - loss: 0.1291 - accuracy: 0.9633 - val_loss: 0.0356 - val_accuracy: 0.9917\n",
            "Epoch 25/30\n",
            "19/19 [==============================] - 54s 3s/step - loss: 0.1271 - accuracy: 0.9650 - val_loss: 0.0309 - val_accuracy: 0.9958\n",
            "Epoch 26/30\n",
            "19/19 [==============================] - 54s 3s/step - loss: 0.0777 - accuracy: 0.9800 - val_loss: 0.0511 - val_accuracy: 0.9833\n",
            "Epoch 27/30\n",
            "19/19 [==============================] - 54s 3s/step - loss: 0.0769 - accuracy: 0.9817 - val_loss: 0.0448 - val_accuracy: 0.9833\n",
            "Epoch 28/30\n",
            "19/19 [==============================] - 54s 3s/step - loss: 0.0869 - accuracy: 0.9667 - val_loss: 0.0207 - val_accuracy: 0.9958\n",
            "Epoch 29/30\n",
            "19/19 [==============================] - 54s 3s/step - loss: 0.0617 - accuracy: 0.9867 - val_loss: 0.0436 - val_accuracy: 0.9917\n",
            "Epoch 30/30\n",
            "19/19 [==============================] - 54s 3s/step - loss: 0.0442 - accuracy: 0.9917 - val_loss: 0.0126 - val_accuracy: 0.9958\n",
            "Sai số kiểm tra là:  0.014559929259121418\n",
            "Độ chính xác kiểm tra là:  1.0\n",
            "Done Train\n",
            "Done Save\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test kiểm tra mô hình train\n",
        "from tensorflow.keras.models import load_model\n",
        "model=load_model('/content/classifier_VietNameseFOOD.h5')\n",
        "from tensorflow.keras.utils import load_img\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "test_img=load_img('/content/(1).jpg',target_size=(150,150))\n",
        "import numpy as np\n",
        "test_img= img_to_array(test_img)\n",
        "test_img=test_img/255\n",
        "test_img=np.expand_dims(test_img,axis=0)\n",
        "result=model.predict(test_img)\n",
        "if round(result[0][0])==1:\n",
        "   prediction=\"BÁNH BAO\"\n",
        "elif round(result[0][1])==1:\n",
        "   prediction=\"BÁNH MÌ\"\n",
        "elif round(result[0][2])==1:\n",
        "   prediction=\"BÁNH TRÁNG NƯỚNG\"  \n",
        "elif round(result[0][3])==1:\n",
        "   prediction=\"BÁNH TRƯNG\"  \n",
        "elif round(result[0][4])==1:\n",
        "   prediction=\"BÁNH TRUNG THU\"  \n",
        "elif round(result[0][5])==1:\n",
        "   prediction=\"BÁNH XÈO\"  \n",
        "elif round(result[0][6])==1:\n",
        "   prediction=\"CHẢ GIÒ\"  \n",
        "elif round(result[0][7])==1:\n",
        "   prediction=\"CƠM TẤM\"  \n",
        "elif round(result[0][8])==1:\n",
        "   prediction=\"GỎI CUỐN\"  \n",
        "elif round(result[0][9])==1:\n",
        "   prediction=\"PHỞ\"  \n",
        "else:\n",
        "  prediction = \" \"\n",
        "print('=====> ĐÂY LÀ MÓN: ' + prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "2Bt4WmokqFjC",
        "outputId": "d7005c8f-e1be-4cdd-98d6-882c5f170b39"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faedd0388c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "=====> ĐÂY LÀ MÓN: BÁNH MÌ\n"
          ]
        }
      ]
    }
  ]
}